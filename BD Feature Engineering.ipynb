{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "178c2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#pip install requests\n",
    "import requests\n",
    "\n",
    "# Omit Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af06bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv(r\"C:\\Users\\braul\\OneDrive\\Desktop\\Academia\\TO NEW BEGINNINGS\\2nd Semester 2024-2025\\Text Mining\\TM Project\\test.csv\")\n",
    "texts = df[\"text\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76017d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text sentiment\n",
      "0   0  ETF assets to surge tenfold in 10 years to $50...  positive\n",
      "1   1  Here’s What Hedge Funds Think Evolution Petrol...   neutral\n",
      "2   2  $PVH - Phillips-Van Heusen Q3 2020 Earnings Pr...   neutral\n",
      "3   3  China is in the process of waiving retaliatory...  negative\n",
      "4   4  Highlight: “When growth is scarce, investors s...   neutral\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Replace 'text' with the actual column name containing your sentences\n",
    "df['sentiment'] = df['text'].apply(lambda x: nlp(str(x))[0]['label'])\n",
    "\n",
    "# Show sample\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50fa99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text sentiment         0  \\\n",
      "0   0  ETF assets to surge tenfold in 10 years to $50...  positive  0.025032   \n",
      "1   1  Here’s What Hedge Funds Think Evolution Petrol...   neutral -0.125657   \n",
      "2   2  $PVH - Phillips-Van Heusen Q3 2020 Earnings Pr...   neutral  0.003956   \n",
      "3   3  China is in the process of waiving retaliatory...  negative  0.121045   \n",
      "4   4  Highlight: “When growth is scarce, investors s...   neutral -0.045187   \n",
      "\n",
      "          1         2         3         4         5         6  ...       758  \\\n",
      "0  0.124286  0.162430 -0.086517  0.069848 -0.056850  0.050488  ...  0.097884   \n",
      "1  0.351593  0.167111 -0.254394  0.069134 -0.130759  0.069325  ... -0.030412   \n",
      "2  0.238421  0.154213  0.121475 -0.053822 -0.110292  0.138608  ...  0.111118   \n",
      "3  0.297020  0.324001 -0.098322 -0.111960 -0.158160  0.205593  ... -0.036597   \n",
      "4  0.194236  0.091016 -0.081666  0.047738  0.051145  0.068032  ...  0.063630   \n",
      "\n",
      "        759       760       761       762       763       764       765  \\\n",
      "0  0.279995 -0.071365 -0.007683  0.046950  0.035155  0.036131 -0.140893   \n",
      "1  0.236165  0.071747  0.188933  0.049468 -0.057074  0.109136 -0.152514   \n",
      "2 -0.006842  0.020445  0.123323  0.103043  0.018393  0.224929 -0.053200   \n",
      "3  0.118868  0.045885  0.038853  0.027291  0.023873 -0.026683  0.042995   \n",
      "4  0.072093  0.092804 -0.067931  0.248610  0.016016  0.139936 -0.222109   \n",
      "\n",
      "        766       767  \n",
      "0  0.095186 -0.069157  \n",
      "1 -0.039292 -0.110604  \n",
      "2 -0.112400 -0.076104  \n",
      "3 -0.008618 -0.073437  \n",
      "4  0.133730 -0.226081  \n",
      "\n",
      "[5 rows x 771 columns]\n"
     ]
    }
   ],
   "source": [
    "# BertTweet model\n",
    "# Load BERTweet tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "model = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "# Set model to evaluation mode and disable gradients\n",
    "model.eval()\n",
    "\n",
    "# Store embeddings\n",
    "embeddings = []\n",
    "\n",
    "for sentence in df['text'].fillna(\"\").astype(str):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the [CLS]-token embedding (first token)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    embeddings.append(cls_embedding)\n",
    "\n",
    "# Convert list of embeddings into a DataFrame (optional)\n",
    "embedding_df = pd.DataFrame(embeddings)\n",
    "\n",
    "# Combine with original data\n",
    "df_with_embeddings = pd.concat([df.reset_index(drop=True), embedding_df], axis=1)\n",
    "\n",
    "# Save the result (optional)\n",
    "df_with_embeddings.to_csv(\"bertweet_embeddings.csv\", index=False)\n",
    "\n",
    "# Display a sample\n",
    "print(df_with_embeddings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ad9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text finbert_prediction\n",
      "0  ETF assets to surge tenfold in 10 years to $50...               None\n",
      "1  Here’s What Hedge Funds Think Evolution Petrol...               None\n",
      "2  $PVH - Phillips-Van Heusen Q3 2020 Earnings Pr...               None\n",
      "3  China is in the process of waiving retaliatory...               None\n",
      "4  Highlight: “When growth is scarce, investors s...               None\n"
     ]
    }
   ],
   "source": [
    "# Load FinTwitBERT pipeline\n",
    "pipe = pipeline(\"fill-mask\", model=\"StephanAkkerman/FinTwitBERT\", framework=\"pt\")\n",
    "\n",
    "# Function to apply the model to each row\n",
    "def apply_mask_prediction(text):\n",
    "    if \"[MASK]\" not in text:\n",
    "        return None  # Skip rows without a mask\n",
    "    try:\n",
    "        result = pipe(text)\n",
    "        # Return the top predicted token (you can customize this)\n",
    "        return result[0]['token_str']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['finbert_prediction'] = df['text'].astype(str).apply(apply_mask_prediction)\n",
    "\n",
    "# Save the result (optional)\n",
    "df.to_csv(\"fintwitbert_predictions.csv\", index=False)\n",
    "\n",
    "# Show a sample\n",
    "print(df[['text', 'finbert_prediction']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
